{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6212f0cb-4afd-445c-904e-c5c2cb659eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 针对最朴素的PointNetv1的一个改进\n",
    "#  改进一、Conv2d改成了Conv1d，这是为了用Batchnorm1d\n",
    "#  改进二、读了GitHub上程序才发现每一层都加了batchnorm1d，遂加上，原文中在图注里讲了，没看到\n",
    "\n",
    "#  待改进、两个Tnet即transform变换没有加入进去\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "class PointNet(nn.Module):\n",
    "    def __init__(self,input_num1,input_num2,out_num):\n",
    "        super(PointNet, self).__init__()\n",
    "        \n",
    "        self.num1 = input_num1\n",
    "        self.block11 = nn.Conv1d(in_channels=input_num1,out_channels=64,kernel_size=1)\n",
    "        self.block21 = nn.Conv1d(in_channels=64,out_channels=64,kernel_size=1)\n",
    "    \n",
    "        self.block31 = nn.Conv1d(in_channels=64,out_channels=128,kernel_size=1)\n",
    "        self.block41 = nn.Conv1d(in_channels=128,out_channels=256,kernel_size=1)\n",
    "    \n",
    "        self.block12 = nn.Conv1d(in_channels=input_num2,out_channels=64,kernel_size=1)\n",
    "        self.block22 = nn.Conv1d(in_channels=64,out_channels=64,kernel_size=1)\n",
    "    \n",
    "        self.block32 = nn.Conv1d(in_channels=64,out_channels=128,kernel_size=1)\n",
    "        self.block42 = nn.Conv1d(in_channels=128,out_channels=256,kernel_size=1)\n",
    "        \n",
    "        self.block1 = nn.Conv1d(in_channels=input_num2,out_channels=64,kernel_size=1)\n",
    "        self.block2 = nn.Conv1d(in_channels=64,out_channels=64,kernel_size=1)\n",
    "    \n",
    "        self.block3 = nn.Conv1d(in_channels=64,out_channels=128,kernel_size=1)\n",
    "        self.block4 = nn.Conv1d(in_channels=128,out_channels=512,kernel_size=1)\n",
    "    \n",
    "    \n",
    "        self.block5 = nn.Conv1d(in_channels=1216,out_channels=512,kernel_size=1)\n",
    "        self.block6 = nn.Conv1d(in_channels=512,out_channels=256,kernel_size=1)\n",
    "        self.block7 = nn.Conv1d(in_channels=256,out_channels=128,kernel_size=1)\n",
    "    \n",
    "        self.bct11 = nn.BatchNorm1d(64)\n",
    "        self.bct21 = nn.BatchNorm1d(64)\n",
    "        self.bct31 = nn.BatchNorm1d(128)\n",
    "        self.bct41 = nn.BatchNorm1d(512)\n",
    "        \n",
    "        self.bct12 = nn.BatchNorm1d(64)\n",
    "        self.bct22 = nn.BatchNorm1d(64)\n",
    "        self.bct32 = nn.BatchNorm1d(128)\n",
    "        self.bct42 = nn.BatchNorm1d(512)\n",
    "        \n",
    "        self.bct5 = nn.BatchNorm1d(512)\n",
    "        self.bct6 = nn.BatchNorm1d(256)\n",
    "        self.bct7 = nn.BatchNorm1d(128)\n",
    "    \n",
    "        self.block8 = nn.Conv1d(in_channels=128,out_channels=out_num,kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1,x2 = x.split(self.num1,1)\n",
    "        n = len(x)\n",
    "        \n",
    "        x = torch.relu(self.bct1(self.block1(x)))\n",
    "        x = torch.relu(self.bct2(self.block2(x)))\n",
    "\n",
    "        y = torch.relu(self.bct3(self.block3(x)))\n",
    "        y = torch.relu(self.bct4(self.block4(y)))\n",
    "        y = torch.max(y, 0, keepdim=True)[0]\n",
    "\n",
    "        \n",
    "        x1 = torch.relu(self.bct11(self.block11(x1)))\n",
    "        x1 = torch.relu(self.bct21(self.block21(x1)))\n",
    "        \n",
    "        y1 = torch.relu(self.bct31(self.block31(x1)))\n",
    "        y1 = torch.relu(self.bct41(self.block41(y1)))\n",
    "        y1 = torch.max(y1, 0, keepdim=True)[0]\n",
    "        \n",
    "        \n",
    "        x2 = torch.relu(self.bct12(self.block12(x2)))\n",
    "        x2 = torch.relu(self.bct22(self.block22(x2)))\n",
    "        \n",
    "        y2 = torch.relu(self.bct32(self.block32(x2)))\n",
    "        y2 = torch.relu(self.bct42(self.block42(y2)))\n",
    "        y2 = torch.max(y2, 0, keepdim=True)[0]\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = torch.cat((x,torch.cat((x1,x2),1)),1)\n",
    "        y = torch.cat((y,torch.cat((y1,y2),1)),1)\n",
    "        \n",
    "        \n",
    "        y = y.repeat(n,1,1)\n",
    "\n",
    "        x = torch.cat((x,y),1)\n",
    "        \n",
    "\n",
    "        x = torch.relu(self.bct5(self.block5(x)))\n",
    "        x = torch.relu(self.bct6(self.block6(x)))\n",
    "        x = torch.relu(self.bct7(self.block7(x)))\n",
    "        \n",
    "        x = self.block8(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c878a925-9649-4421-850b-37df5551cfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = PointNet(2,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f776ed-cde4-41aa-a35b-80496c1f0e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda, float32\n",
    "@cuda.jit\n",
    "def compute_G2(G2_r, G2_i, x, c, k, const, ver_num):\n",
    "    p, i, j = cuda.grid(3)\n",
    "    if p < G2_r.shape[0] and i < G2_r.shape[1] and j < G2_r.shape[2]:\n",
    "        if not (i in ver_num):\n",
    "            p_n = 0.0\n",
    "            for d in range(2):\n",
    "                r = x[p,i,d]-x[p,:,d]\n",
    "                p_n += c[p,i,d]*r\n",
    "            d = 0.0\n",
    "            for d in range(2):\n",
    "                d += (x[p,i,d]-x[p,j,d])**2\n",
    "            d = math.sqrt(d)\n",
    "            h1 = hankel1(1,k*d)\n",
    "            G2_r[p,i,j] = -( h1.imag/4*(p_n)/d*k )\n",
    "            G2_i[p,i,j] = -( -h1.real/4*(p_n)/d*k )\n",
    "            if i == j:\n",
    "                G2_r[p,i,j] = -const\n",
    "                G2_i[p,i,j] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "204d440d-8b9b-4d7a-8651-02e2405ed5d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cusolver'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mscp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcusolver\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m G2_r_gpu \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mzeros_like(G2_r)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cusolver'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.special as scp\n",
    "import cusolver\n",
    "import cupy as cp\n",
    "\n",
    "G2_r_gpu = cp.zeros_like(G2_r)\n",
    "G2_i_gpu = cp.zeros_like(G2_i)\n",
    "d_gpu = cp.zeros_like(d)\n",
    "\n",
    "for p in range(sample_tri):\n",
    "    for i in range(N):\n",
    "        if not i in ver_num:\n",
    "            r = x[p, i, :] - x[p, :, :]\n",
    "            p_n = (c[p, :, :] * r).sum(axis=1)\n",
    "            d = cp.sqrt(cp.square(r[:, 0]) + cp.square(r[:, 1]))\n",
    "\n",
    "            # 在GPU上计算Hankel函数\n",
    "            hankel1_imag = cp.zeros_like(d)\n",
    "            hankel1_real = cp.zeros_like(d)\n",
    "            cusolver.cusolverDnSbessel_J0(hankel1_imag.data.ptr, d.data.ptr, d.shape[0])\n",
    "            cusolver.cusolverDnSbessel_Y0(hankel1_real.data.ptr, d.data.ptr, d.shape[0])\n",
    "            \n",
    "            # 将结果存储在GPU内存中\n",
    "            G2_r_gpu[p, i, :] = -hankel1_imag / 4 * p_n / d * k\n",
    "            G2_i_gpu[p, i, :] = -hankel1_real / 4 * p_n / d * k\n",
    "            G2_r_gpu[p, i, i], G2_i_gpu[p, i, i] = -const, 0\n",
    "            \n",
    "            G2_r = cp.asnumpy(G2_r_gpu)\n",
    "            G2_i = cp.asnumpy(G2_i_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc71f7f-c43c-4509-842a-b767ccc3e058",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
